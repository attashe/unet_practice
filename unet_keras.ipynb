{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Attashe\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unet(pretrained_weights = None,input_size = (256,256,1)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = merge([drop4,up6], mode = 'concat', concat_axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = merge([conv3,up7], mode = 'concat', concat_axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = merge([conv2,up8], mode = 'concat', concat_axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = merge([conv1,up9], mode = 'concat', concat_axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input = inputs, output = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    #model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "    \tmodel.load_weights(pretrained_weights)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'E:/GitHub/kaggle_cells/data/stage1_train/'\n",
    "\n",
    "train_ids = os.listdir(TRAIN_DIR)\n",
    "train_images = [os.path.join(TRAIN_DIR, train_id, 'images', train_id + '.png') \n",
    "                for train_id in train_ids]\n",
    "train_masks = {train_id: [os.path.join(TRAIN_DIR, train_id, 'masks', img_name) \n",
    "                          for img_name in os.listdir(os.path.join(TRAIN_DIR, train_id, 'masks'))]\n",
    "               for train_id in train_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {train_ids[i]: cv2.imread(train_images[i]) for i in range(len(train_images))}\n",
    "\n",
    "Y = {train_id: sum((cv2.imread(train_mask)[..., 0]\n",
    "                    for train_mask in train_masks[train_id]))\n",
    "     for train_id in train_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(670, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((len(train_ids),) + X[train_ids[0]].shape)\n",
    "y = np.zeros((len(train_ids),) + Y[train_ids[0]].shape)\n",
    "# assert(X[train_ids[0]].shape == Y[train_ids[0]].shape)\n",
    "print(x.shape)\n",
    "\n",
    "for i, ind in zip(range(len(train_ids)), train_ids):\n",
    "    x[i,:, :, :] =  cv2.resize(X[ind], (256, 256))\n",
    "    y[i, :, :] = cv2.resize(Y[ind], (256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27502375c88>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAC7CAYAAABrY1U1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nehGRgft/cyJsg1RvsCUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(x[12])\n",
    "plt.subplot(122)\n",
    "plt.imshow(y[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generator(x, y, batch_size=10):\n",
    "    for i in range(len(x) // batch_size):\n",
    "        yield (x[i*batch_size:i*batch_size+batch_size], \n",
    "               y[i*batch_size:i*batch_size+batch_size])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Attashe\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "C:\\Users\\Attashe\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\keras\\legacy\\layers.py:464: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "C:\\Users\\Attashe\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "C:\\Users\\Attashe\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "C:\\Users\\Attashe\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:37: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "C:\\Users\\Attashe\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:43: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected conv2d_192 to have shape (256, 256, 1) but got array with shape (1, 256, 256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-f52d328f9667>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#model_checkpoint = ModelCheckpoint  # ('unet_membrane.hdf5', monitor='loss',verbose=1, save_best_only=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m model.fit_generator(data_generator(x, y.reshape((-1, 1, 256, 256))/255, 2)\n\u001b[1;32m---> 12\u001b[1;33m                     ,steps_per_epoch=2000,epochs=5)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2175\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2176\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1841\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1843\u001b[1;33m             check_batch_axis=True)\n\u001b[0m\u001b[0;32m   1844\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1845\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[0;32m   1428\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1430\u001b[1;33m                                     exception_prefix='target')\n\u001b[0m\u001b[0;32m   1431\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[0;32m   1432\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    118\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    121\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected conv2d_192 to have shape (256, 256, 1) but got array with shape (1, 256, 256)"
     ]
    }
   ],
   "source": [
    "# data_gen_args = dict(rotation_range=0.2,\n",
    "#                     width_shift_range=0.05,\n",
    "#                     height_shift_range=0.05,\n",
    "#                     shear_range=0.05,\n",
    "#                     zoom_range=0.05,\n",
    "#                     horizontal_flip=True,\n",
    "#                     fill_mode='nearest')\n",
    "#myGene = trainGenerator  # (2,'data/membrane/train','image','label',data_gen_args,save_to_dir = None)\n",
    "model = unet(input_size=(256, 256, 3))\n",
    "#model_checkpoint = ModelCheckpoint  # ('unet_membrane.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "model.fit_generator(data_generator(x, y.reshape((-1, 1, 256, 256))/255, 2)\n",
    "                    ,steps_per_epoch=2000,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670, 256, 256, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
